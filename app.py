import streamlit as st
import pandas as pd
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
from io import StringIO
import re
from urllib.parse import urlparse

# ---------------- Page Setup ----------------
st.set_page_config(page_title="App-ads.txt Health Checker", layout="wide")
st.title("üõ°Ô∏è App-ads.txt Health & Line Counter")
st.markdown("""
–≠—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –ø—Ä–æ–≤–µ—Ä—è–µ—Ç –Ω–∞–ª–∏—á–∏–µ —Ñ–∞–π–ª–∞ **app-ads.txt**, –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ä–µ–¥–∏—Ä–µ–∫—Ç—ã, 
–∏–≥–Ω–æ—Ä–∏—Ä—É–µ—Ç HTML-—Å—Ç—Ä–∞–Ω–∏—Ü—ã –æ—à–∏–±–æ–∫ (Soft 404) –∏ —Å—á–∏—Ç–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≤–∞–ª–∏–¥–Ω—ã—Ö —Å—Ç—Ä–æ–∫.
**–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—ã–≤–æ–¥—è—Ç—Å—è –≤ —Ç–æ–º –∂–µ –ø–æ—Ä—è–¥–∫–µ, —á—Ç–æ –∏ –≤ –≤–∞—à–µ–º —Å–ø–∏—Å–∫–µ.**
""")

# ---------------- Input Tabs ----------------
tab1, tab2 = st.tabs(["üìã –í—Å—Ç–∞–≤–∏—Ç—å —Å–ø–∏—Å–æ–∫", "üìÇ –ó–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª"])

domains = []
with tab1:
    st.header("–°–ø–∏—Å–æ–∫ –¥–æ–º–µ–Ω–æ–≤")
    domain_input = st.text_area("–í—Å—Ç–∞–≤—å—Ç–µ –¥–æ–º–µ–Ω—ã (–æ–¥–∏–Ω –Ω–∞ —Å—Ç—Ä–æ–∫—É)", height=200)
    if domain_input:
        domains = [d.strip() for d in domain_input.splitlines() if d.strip()]

with tab2:
    st.header("–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–∞")
    uploaded_file = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ CSV –∏–ª–∏ TXT —Ñ–∞–π–ª", type=["csv", "txt"])
    if uploaded_file:
        stringio = StringIO(uploaded_file.getvalue().decode("utf-8"))
        uploaded_domains = [line.strip() for line in stringio.readlines() if line.strip()]
        domains.extend(uploaded_domains)

# Deduplicate preserving order (Python 3.7+ dict preserves insertion order)
domains = list(dict.fromkeys(domains))

if domains:
    st.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –¥–æ–º–µ–Ω–æ–≤: {len(domains)}")

# ---------------- Settings Sidebar ----------------
st.sidebar.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")

timeout_sec = st.sidebar.slider("–¢–∞–π–º-–∞—É—Ç –∑–∞–ø—Ä–æ—Å–∞ (—Å–µ–∫)", 3, 20, 5)
max_threads = st.sidebar.slider("–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤", 5, 50, 30)
ua_mode = st.sidebar.radio("–†–µ–∂–∏–º User-Agent", ["Chrome (Windows)", "Google Bot"])

if ua_mode == "Chrome (Windows)":
    USER_AGENT = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
else:
    USER_AGENT = "Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)"

# ---------------- Logic Functions ----------------

def clean_domain(raw_url):
    """–û—á–∏—â–∞–µ—Ç –≤–≤–æ–¥, –æ—Å—Ç–∞–≤–ª—è—è —Ç–æ–ª—å–∫–æ –¥–æ–º–µ–Ω –∏–ª–∏ –±–∞–∑–æ–≤—ã–π URL –±–µ–∑ —Ö–≤–æ—Å—Ç–æ–≤."""
    raw_url = raw_url.strip()
    if not raw_url.startswith("http"):
        raw_url = "http://" + raw_url
    try:
        parsed = urlparse(raw_url)
        return parsed.netloc + parsed.path.rstrip('/')
    except:
        return raw_url

def analyze_content(text):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç–µ–∫—Å—Ç —Ñ–∞–π–ª–∞."""
    if not text:
        return 0, "Empty File"
    
    text_lower = text.lower()[:500] 
    if "<!doctype html" in text_lower or "<html" in text_lower or "<body" in text_lower or "<div" in text_lower:
        return 0, "Soft 404 (HTML)"

    lines = text.splitlines()
    valid_count = 0
    for line in lines:
        line = line.strip()
        if line and not line.startswith('#'):
            valid_count += 1
    
    if valid_count == 0:
        return 0, "Empty File"
    
    return valid_count, "Valid"

def check_domain(domain, index):
    """
    –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ–º–µ–Ω–∞.
    –ê—Ä–≥—É–º–µ–Ω—Ç index –Ω—É–∂–µ–Ω, —á—Ç–æ–±—ã –∑–∞–ø–æ–º–Ω–∏—Ç—å –ø–æ—Ä—è–¥–∫–æ–≤—ã–π –Ω–æ–º–µ—Ä.
    """
    clean_d = clean_domain(domain)
    target_url = f"https://{clean_d}/app-ads.txt"
    
    session = requests.Session()
    session.headers.update({'User-Agent': USER_AGENT})
    
    result = {
        "Index": index, # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π –Ω–æ–º–µ—Ä —Å—Ç—Ä–æ–∫–∏
        "Input Domain": domain,
        "Final URL": target_url,
        "Status": "Unknown",
        "Code": 0,
        "Lines": 0
    }

    try:
        # –ü–æ–ø—ã—Ç–∫–∞ 1: HTTPS
        response = session.get(target_url, timeout=timeout_sec, allow_redirects=True)
    except requests.exceptions.SSLError:
        # –ü–æ–ø—ã—Ç–∫–∞ 2: HTTPS –±–µ–∑ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞
        try:
            response = session.get(target_url, timeout=timeout_sec, allow_redirects=True, verify=False)
        except Exception:
             # –ü–æ–ø—ã—Ç–∫–∞ 3: HTTP
            try:
                target_url_http = f"http://{clean_d}/app-ads.txt"
                response = session.get(target_url_http, timeout=timeout_sec, allow_redirects=True)
                result["Final URL"] = response.url
            except Exception:
                result["Status"] = "Connection Error"
                result["Code"] = "ERR"
                return result
    except Exception:
        result["Status"] = "Connection Error"
        result["Code"] = "ERR"
        return result

    result["Code"] = response.status_code
    result["Final URL"] = response.url

    if response.status_code == 200:
        count, status_msg = analyze_content(response.text)
        result["Lines"] = count
        result["Status"] = status_msg
    elif response.status_code == 403:
        result["Status"] = "Forbidden"
    elif response.status_code == 404:
        result["Status"] = "Not Found"
    else:
        result["Status"] = f"HTTP {response.status_code}"

    return result

# ---------------- Main Execution ----------------

if st.button("üöÄ –ù–∞—á–∞—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É", disabled=not domains):
    start_time = time.time()
    results_data = []
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø–æ—Ç–æ–∫–∏, –ø–µ—Ä–µ–¥–∞–≤–∞—è –∏–Ω–¥–µ–∫—Å (i)
    with ThreadPoolExecutor(max_workers=max_threads) as executor:
        # –ü–µ—Ä–µ–¥–∞–µ–º enumerate(domains), —á—Ç–æ–±—ã —É –∫–∞–∂–¥–æ–≥–æ –¥–æ–º–µ–Ω–∞ –±—ã–ª —Å–≤–æ–π –Ω–æ–º–µ—Ä (0, 1, 2...)
        future_to_domain = {executor.submit(check_domain, d, i): d for i, d in enumerate(domains)}
        
        for i, future in enumerate(as_completed(future_to_domain)):
            data = future.result()
            results_data.append(data)
            
            percent = (i + 1) / len(domains)
            progress_bar.progress(percent)
            status_text.text(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {i + 1} –∏–∑ {len(domains)}...")

    end_time = time.time()
    st.success(f"‚úÖ –ì–æ—Ç–æ–≤–æ! –ó–∞—Ç—Ä–∞—á–µ–Ω–æ –≤—Ä–µ–º–µ–Ω–∏: {end_time - start_time:.2f} —Å–µ–∫.")

    # ---------------- Display Results ----------------
    df = pd.DataFrame(results_data)
    
    # === –í–ê–ñ–ù–û: –°–æ—Ä—Ç–∏—Ä—É–µ–º –æ–±—Ä–∞—Ç–Ω–æ –ø–æ –∏–Ω–¥–µ–∫—Å—É ===
    if not df.empty:
        df = df.sort_values(by=["Index"], ascending=True)
        # –£–¥–∞–ª—è–µ–º –∫–æ–ª–æ–Ω–∫—É Index, —á—Ç–æ–±—ã –æ–Ω–∞ –Ω–µ –º–µ—à–∞–ª–∞—Å—å –≤ —Ç–∞–±–ª–∏—Ü–µ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ, –Ω–æ —Ç–∞–∫ –∫—Ä–∞—Å–∏–≤–µ–µ)
        df_display = df.drop(columns=["Index"]) 
    else:
        df_display = df

    def highlight_status(val):
        color = 'black'
        if val == 'Valid':
            color = 'green'
        elif val == 'Not Found' or val == 'Empty File' or val == 'Connection Error':
            color = 'red'
        elif 'Soft 404' in val or 'Forbidden' in val:
            color = 'orange'
        return f'color: {color}; font-weight: bold'

    st.subheader("üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–æ–≤–µ—Ä–∫–∏")
    st.dataframe(
        df_display.style.map(highlight_status, subset=['Status']),
        use_container_width=True,
        column_config={
            "Final URL": st.column_config.LinkColumn("–°—Å—ã–ª–∫–∞ –Ω–∞ —Ñ–∞–π–ª"),
            "Lines": st.column_config.NumberColumn("–ö–æ–ª-–≤–æ —Å—Ç—Ä–æ–∫", format="%d")
        }
    )

    # ---------------- Export ----------------
    # –î–ª—è CSV –±–µ—Ä–µ–º –æ—Ç—Å–æ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ—Ä–µ–π–º, –Ω–æ –±–µ–∑ –∫–æ–ª–æ–Ω–∫–∏ Index
    csv = df_display.to_csv(index=False).encode('utf-8')
    st.download_button(
        label="üì• –°–∫–∞—á–∞—Ç—å –æ—Ç—á–µ—Ç (CSV)",
        data=csv,
        file_name='app_ads_report.csv',
        mime='text/csv',
    )
